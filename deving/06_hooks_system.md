# CrewAI Hooks æœºåˆ¶è¯¦è§£

## 1. Hooks ç±»å‹

| Hook ç±»å‹ | è§¦å‘æ—¶æœº | åŠŸèƒ½ |
|-----------|---------|------|
| **`@before_llm_call`** | LLM è°ƒç”¨å‰ | ä¿®æ”¹æ¶ˆæ¯ã€é˜»æ­¢æ‰§è¡Œ |
| **`@after_llm_call`** | LLM è°ƒç”¨å | ä¿®æ”¹å“åº”ã€è®°å½•æ—¥å¿— |
| **`@before_tool_call`** | å·¥å…·è°ƒç”¨å‰ | ä¿®æ”¹è¾“å…¥ã€é˜»æ­¢æ‰§è¡Œ |
| **`@after_tool_call`** | å·¥å…·è°ƒç”¨å | ä¿®æ”¹è¾“å‡ºã€è®°å½•ç»“æœ |

## 2. åŸºæœ¬ç”¨æ³•

### LLM Hooks

```python
from crewai import Agent, Task, Crew
from crewai.hooks import before_llm_call, after_llm_call

@before_llm_call
def log_llm_calls(context):
    """è®°å½•æ‰€æœ‰ LLM è°ƒç”¨"""
    print(f"LLM call by {context.agent.role}")
    print(f"Iterations: {context.iterations}")
    return None

@after_llm_call
def sanitize_response(context):
    """æ¸…ç†æ•æ„Ÿä¿¡æ¯"""
    if context.response and "SECRET" in context.response:
        return context.response.replace("SECRET", "[REDACTED]")
    return None

agent = Agent(role="Assistant", goal="Help users")
task = Task(description="Say hello", agent=agent)
crew = Crew(agents=[agent], tasks=[task])
result = crew.kickoff()
```

### Tool Hooks

```python
from crewai.hooks import before_tool_call, after_tool_call

@before_tool_call
def log_tool_usage(context):
    print(f"Tool: {context.tool_name}")
    return None

@after_tool_call
def log_results(context):
    print(f"Result: {context.tool_result[:100]}")
    return None
```

## 3. è¿‡æ»¤ Hooksï¼ˆé«˜çº§åŠŸèƒ½ï¼‰

### æŒ‰ Agent è¿‡æ»¤

```python
@before_llm_call(agents=["Researcher", "Analyst"])
def log_specific_agents(context):
    """åªè®°å½•ç‰¹å®š Agent"""
    print(f"Filtered LLM call: {context.agent.role}")
    return None
```

### æŒ‰ Tool è¿‡æ»¤

```python
@before_tool_call(tools=["delete_file", "execute_code"])
def approve_dangerous(context):
    """å±é™©å·¥å…·éœ€è¦äººå·¥ç¡®è®¤"""
    response = context.request_human_input(
        prompt=f"âš ï¸  Allow {context.tool_name}?",
        default_message="Type 'yes' to approve:"
    )
    if response.lower() != "yes":
        return False  # é˜»æ­¢æ‰§è¡Œ
    return None
```

### ç»„åˆè¿‡æ»¤

```python
@before_tool_call(tools=["write_file"], agents=["Developer"])
def approve_dev_writes(context):
    """åªæœ‰ Developer å†™æ–‡ä»¶æ—¶éœ€è¦å®¡æ‰¹"""
    return None
```

## 4. Hook Context å¯¹è±¡

### LLMCallHookContext

```python
class LLMCallHookContext:
    executor: CrewAgentExecutor | LiteAgent | None
    messages: list[LLMMessage]      # å¯å˜åˆ—è¡¨ï¼Œå¯å°±åœ°ä¿®æ”¹
    agent: Agent                     # å½“å‰ Agent
    task: Task                       # å½“å‰ Task
    crew: Crew                       # å½“å‰ Crew
    llm: BaseLLM                     # LLM å®ä¾‹
    iterations: int                  # å½“å‰è¿­ä»£æ¬¡æ•°
    response: str | None             # LLM å“åº”ï¼ˆä»… after hooksï¼‰

    def request_human_input(self, prompt, default_message):
        """è¯·æ±‚äººå·¥è¾“å…¥"""
```

### ToolCallHookContext

```python
class ToolCallHookContext:
    tool_name: str
    tool_input: dict[str, Any]      # å¯å˜å­—å…¸ï¼Œå¯å°±åœ°ä¿®æ”¹
    tool: CrewStructuredTool         # å·¥å…·å®ä¾‹
    agent: Agent                     # æ‰§è¡Œå·¥å…·çš„ Agent
    task: Task                       # å½“å‰ Task
    crew: Crew                       # å½“å‰ Crew
    tool_result: str | None          # å·¥å…·ç»“æœï¼ˆä»… after hooksï¼‰

    def request_human_input(self, prompt, default_message):
        """è¯·æ±‚äººå·¥è¾“å…¥"""
```

## 5. å®é™…åº”ç”¨ç¤ºä¾‹

### å®‰å…¨å®¡è®¡

```python
@before_llm_call
def audit_log(context):
    """è®°å½•æ‰€æœ‰ LLM è°ƒç”¨"""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": context.agent.role,
        "iterations": context.iterations
    }
    with open("audit_log.jsonl", "a") as f:
        f.write(json.dumps(log_entry) + "\n")
    return None

@before_tool_call(tools=["delete_file", "execute_code"])
def security_gate(context):
    """å±é™©å·¥å…·éœ€è¦äºŒæ¬¡ç¡®è®¤"""
    approval = context.request_human_input(
        prompt="Approve this tool call?",
        default_message="Type 'approve' to continue:"
    )
    return approval.lower() == "approve"
```

### æˆæœ¬æ§åˆ¶

```python
@before_llm_call
def limit_iterations(context):
    """é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•°"""
    if context.iterations >= 10:
        print("âš ï¸  Max iterations reached!")
        return False  # é˜»æ­¢æ‰§è¡Œ
    return None

@after_llm_call
def track_tokens(context):
    """ç»Ÿè®¡ token ä½¿ç”¨"""
    input_tokens = sum(len(str(msg.content)) for msg in context.messages) // 4
    output_tokens = len(context.response) // 4 if context.response else 0
    print(f"ğŸ’° Tokens: {input_tokens} + {output_tokens} = {input_tokens + output_tokens}")
    return None
```

### å†…å®¹è¿‡æ»¤

```python
@after_llm_call
def filter_sensitive_content(context):
    """è¿‡æ»¤æ•æ„Ÿå†…å®¹"""
    if not context.response:
        return None

    sensitive_words = ["API_KEY", "SECRET", "PASSWORD"]
    filtered_response = context.response

    for word in sensitive_words:
        if word in filtered_response:
            filtered_response = filtered_response.replace(word, f"[REDACTED]")

    return filtered_response
```

### åŠ¨æ€ä¿®æ”¹æ¶ˆæ¯

```python
@before_llm_call
def inject_system_prompt(context):
    """åŠ¨æ€æ³¨å…¥ç³»ç»Ÿæç¤º"""
    from crewai.utilities.types import LLMMessage

    system_message = LLMMessage(
        role="system",
        content="IMPORTANT: Always respond in JSON format."
    )

    context.messages.insert(0, system_message)
    return None

@before_llm_call(agents=["Researcher"])
def enhance_researcher_context(context):
    """ä¸ºç‰¹å®š Agent æ·»åŠ é¢å¤–ä¸Šä¸‹æ–‡"""
    from crewai.utilities.types import LLMMessage

    enhancement = LLMMessage(
        role="user",
        content="\n\nRemember to cite your sources!"
    )

    context.messages.append(enhancement)
    return None
```

## 6. ä¸ Claude Hooks å¯¹æ¯”

| ç‰¹æ€§ | CrewAI | Claude |
|------|--------|-------|
| LLM è°ƒç”¨å‰ Hook | âœ… `@before_llm_call` | âœ… `on_before_llm_call` |
| LLM è°ƒç”¨å Hook | âœ… `@after_llm_call` | âœ… `on_after_llm_call` |
| å·¥å…·è°ƒç”¨å‰ Hook | âœ… `@before_tool_call` | âœ… `on_before_tool_use` |
| å·¥å…·è°ƒç”¨å Hook | âœ… `@after_tool_call` | âœ… `on_after_tool_use` |
| Agent è¿‡æ»¤ | âœ… `agents=["..."]` | âš ï¸ æ‰‹åŠ¨åˆ¤æ–­ |
| Tool è¿‡æ»¤ | âœ… `tools=["..."]` | âš ï¸ æ‰‹åŠ¨åˆ¤æ–­ |
| äººå·¥è¾“å…¥ | âœ… `request_human_input()` | âš ï¸ éœ€è¦è‡ªå·±å®ç° |
| ä¿®æ”¹æ¶ˆæ¯ | âœ… å°±åœ°ä¿®æ”¹ `messages` | âœ… å°±åœ°ä¿®æ”¹ |
| ä¿®æ”¹å“åº” | âœ… è¿”å›æ–°å­—ç¬¦ä¸² | âœ… è¿”å›æ–°å­—ç¬¦ä¸² |
| é˜»æ­¢æ‰§è¡Œ | âœ… è¿”å› `False` | âœ… æŠ›å‡ºå¼‚å¸¸ |

## 7. åŠ¨æ€æ³¨å†Œ Hooks

```python
from crewai.hooks import (
    register_before_llm_call_hook,
    unregister_before_llm_call_hook,
    clear_all_global_hooks
)

# å®šä¹‰ hook
def my_llm_hook(context):
    print("Custom LLM hook")
    return None

# æ³¨å†Œ
register_before_llm_call_hook(my_llm_hook)

# ä½¿ç”¨
crew.kickoff()

# æ³¨é”€
unregister_before_llm_call_hook(my_llm_hook)

# æ¸…é™¤æ‰€æœ‰
clear_all_global_hooks()
```

## 8. æ¨èä½¿ç”¨åœºæ™¯

- âœ… **å®‰å…¨å®¡è®¡**ï¼šè®°å½•æ‰€æœ‰ LLM å’Œå·¥å…·è°ƒç”¨
- âœ… **æˆæœ¬æ§åˆ¶**ï¼šé™åˆ¶è¿­ä»£æ¬¡æ•°ã€ç»Ÿè®¡ token
- âœ… **å†…å®¹è¿‡æ»¤**ï¼šè¿‡æ»¤æ•æ„Ÿä¿¡æ¯
- âœ… **äººå·¥å®¡æ ¸**ï¼šå±é™©æ“ä½œéœ€è¦äººå·¥ç¡®è®¤
- âœ… **åŠ¨æ€æç¤º**ï¼šè¿è¡Œæ—¶ä¿®æ”¹ç³»ç»Ÿæç¤º
- âœ… **è°ƒè¯•æ—¥å¿—**ï¼šè®°å½•è¯¦ç»†çš„æ‰§è¡Œè¿‡ç¨‹
